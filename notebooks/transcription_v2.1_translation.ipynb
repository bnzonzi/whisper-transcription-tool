{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whisper Transcription + Translation Tool v2.1\n",
    "\n",
    "## Version avec traduction automatique vers le fran√ßais\n",
    "\n",
    "### Nouvelles fonctionnalit√©s v2.1 :\n",
    "- üåç **D√©tection automatique de langue** source\n",
    "- üîÑ **Traduction vers le fran√ßais** avec services multiples  \n",
    "- üìù **Export bilingue** (original + fran√ßais)\n",
    "- üéØ **Post-traitement fran√ßais** optimis√©\n",
    "- üîß **Choix du service de traduction** (DeepL, Google)\n",
    "- üìä **M√©tadonn√©es √©tendues** (langue source, confiance)\n",
    "\n",
    "### Configuration rapide :\n",
    "1. Modifiez les variables `TRANSLATION_SERVICE` et `SOURCE_INPUT`\n",
    "2. Ex√©cutez toutes les cellules\n",
    "3. R√©cup√©rez vos fichiers traduits en fran√ßais !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation\n",
    "!pip install -q ffmpeg yt_dlp huggingface_hub\n",
    "!pip install -q git+https://github.com/openai/whisper.git\n",
    "!pip install -q torch torchaudio torchvision\n",
    "!pip install -q deepl googletrans==4.0.0rc1 language-tool-python\n",
    "\n",
    "# Imports\n",
    "import os, subprocess, glob, zipfile, time, json, re\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "import torch\n",
    "import whisper\n",
    "from yt_dlp import YoutubeDL\n",
    "\n",
    "# Services de traduction\n",
    "try:\n",
    "    import deepl\n",
    "    DEEPL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    DEEPL_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from googletrans import Translator as GoogleTranslator\n",
    "    GOOGLE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    GOOGLE_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import language_tool_python\n",
    "    LANGUAGE_TOOL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    LANGUAGE_TOOL_AVAILABLE = False\n",
    "\n",
    "print(f\"‚úÖ Services disponibles:\")\n",
    "print(f\"  - DeepL: {'‚úÖ' if DEEPL_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"  - Google Translate: {'‚úÖ' if GOOGLE_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"  - Language Tool: {'‚úÖ' if LANGUAGE_TOOL_AVAILABLE else '‚ùå'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION PRINCIPALE ===\n",
    "TRANSLATION_SERVICE = \"auto\"      # \"auto\", \"deepl\", \"google\"\n",
    "SOURCE_TYPE = \"1\"                 # \"1\"=URL, \"2\"=Dossier, \"3\"=Fichier\n",
    "SOURCE_INPUT = \"https://www.youtube.com/watch?v=afUrxn0NT2s\"  # Modifiez cette URL\n",
    "\n",
    "# Param√®tres avanc√©s\n",
    "EXPORT_BILINGUAL = True\n",
    "IMPROVE_FRENCH = True\n",
    "temp_directory = '/kaggle/working'\n",
    "whisper_model_name = \"large-v3\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Configuration des API\n",
    "DEEPL_API_KEY = os.environ.get('DEEPL_API_KEY', None)\n",
    "translators = {}\n",
    "\n",
    "if DEEPL_AVAILABLE and DEEPL_API_KEY:\n",
    "    try:\n",
    "        translators['deepl'] = deepl.Translator(DEEPL_API_KEY)\n",
    "        print(\"‚úÖ DeepL configur√©\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur DeepL: {e}\")\n",
    "\n",
    "if GOOGLE_AVAILABLE:\n",
    "    try:\n",
    "        translators['google'] = GoogleTranslator()\n",
    "        print(\"‚úÖ Google Translate configur√©\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur Google: {e}\")\n",
    "\n",
    "if LANGUAGE_TOOL_AVAILABLE and IMPROVE_FRENCH:\n",
    "    try:\n",
    "        grammar_checker = language_tool_python.LanguageTool('fr')\n",
    "        print(\"‚úÖ Correcteur fran√ßais configur√©\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur correcteur: {e}\")\n",
    "        grammar_checker = None\n",
    "else:\n",
    "    grammar_checker = None\n",
    "\n",
    "print(f\"\\nüéØ WHISPER TRANSCRIPTION + TRANSLATION TOOL v2.1\")\n",
    "print(f\"üîß Device : {device}\")\n",
    "print(f\"üåç Service traduction : {TRANSLATION_SERVICE}\")\n",
    "print(f\"üìÅ Source : {['', 'URL', 'Dossier', 'Fichier'][int(SOURCE_TYPE)]}\")\n",
    "print(f\"üìÑ Input : {SOURCE_INPUT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_timestamp(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    secs = int(seconds % 60)\n",
    "    milliseconds = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{secs:02},{milliseconds:03}\"\n",
    "\n",
    "def detect_file_type(filepath):\n",
    "    audio_extensions = ('.mp3', '.wav', '.aac', '.flac', '.ogg', '.m4a')\n",
    "    video_extensions = ('.mp4', '.avi', '.mkv', '.webm', '.mov', '.flv')\n",
    "    filepath_lower = filepath.lower()\n",
    "    if filepath_lower.endswith(audio_extensions):\n",
    "        return \"audio\"\n",
    "    elif filepath_lower.endswith(video_extensions):\n",
    "        return \"video\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "def detect_language(model, audio_path):\n",
    "    try:\n",
    "        audio = whisper.load_audio(audio_path)\n",
    "        audio = whisper.pad_or_trim(audio, length=30 * 16000)\n",
    "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "        _, probs = model.detect_language(mel)\n",
    "        detected_language = max(probs, key=probs.get)\n",
    "        confidence = probs[detected_language]\n",
    "        return detected_language, confidence\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur d√©tection langue: {e}\")\n",
    "        return \"en\", 0.5\n",
    "\n",
    "def get_language_name(code):\n",
    "    languages = {\n",
    "        'en': 'Anglais', 'fr': 'Fran√ßais', 'es': 'Espagnol', 'de': 'Allemand',\n",
    "        'it': 'Italien', 'pt': 'Portugais', 'ru': 'Russe', 'ja': 'Japonais'\n",
    "    }\n",
    "    return languages.get(code, f\"Langue ({code})\")\n",
    "\n",
    "def translate_text(text: str, service: str = \"auto\") -> Tuple[str, str]:\n",
    "    if not text or not text.strip():\n",
    "        return text, \"none\"\n",
    "    \n",
    "    services_order = ['deepl', 'google'] if service == \"auto\" else [service]\n",
    "    \n",
    "    for svc in services_order:\n",
    "        try:\n",
    "            if svc == 'deepl' and 'deepl' in translators:\n",
    "                result = translators['deepl'].translate_text(text, target_lang=\"FR\")\n",
    "                return result.text, \"deepl\"\n",
    "            elif svc == 'google' and 'google' in translators:\n",
    "                result = translators['google'].translate(text, dest=\"fr\")\n",
    "                return result.text, \"google\"\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur {svc}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return text, \"failed\"\n",
    "\n",
    "def improve_french_text(text: str) -> str:\n",
    "    if not IMPROVE_FRENCH or not grammar_checker:\n",
    "        return text\n",
    "    try:\n",
    "        matches = grammar_checker.check(text)\n",
    "        corrected_text = language_tool_python.utils.correct(text, matches)\n",
    "        corrected_text = re.sub(r'\\s+', ' ', corrected_text)\n",
    "        return corrected_text.strip()\n",
    "    except Exception as e:\n",
    "        return text\n",
    "\n",
    "print(\"‚úÖ Fonctions utilitaires d√©finies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chargement du mod√®le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ü§ñ Chargement du mod√®le Whisper '{whisper_model_name}' sur {device}...\")\n",
    "whisper_model = whisper.load_model(whisper_model_name, device=device)\n",
    "print(\"‚úÖ Mod√®le Whisper charg√© avec succ√®s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Traitement principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©paration\n",
    "os.makedirs(temp_directory, exist_ok=True)\n",
    "files_to_process = []\n",
    "generated_files = []\n",
    "\n",
    "print(\"üöÄ D√©but du traitement...\")\n",
    "\n",
    "# Gestion des sources\n",
    "if SOURCE_TYPE == \"1\":  # URL\n",
    "    print(f\"üì• T√©l√©chargement : {SOURCE_INPUT}\")\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo+bestaudio/best',\n",
    "        'outtmpl': os.path.join(temp_directory, '%(title)s.%(ext)s'),\n",
    "        'noplaylist': True,\n",
    "        'quiet': True,\n",
    "    }\n",
    "    \n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.extract_info(SOURCE_INPUT, download=True)\n",
    "    \n",
    "    video_files = glob.glob(os.path.join(temp_directory, \"*\"))\n",
    "    video_files = [f for f in video_files if detect_file_type(f) in [\"video\", \"audio\"]]\n",
    "    if video_files:\n",
    "        downloaded_file = max(video_files, key=os.path.getctime)\n",
    "        files_to_process.append(downloaded_file)\n",
    "        print(f\"‚úÖ T√©l√©charg√© : {os.path.basename(downloaded_file)}\")\n",
    "\n",
    "elif SOURCE_TYPE == \"2\":  # Dossier\n",
    "    extensions = ['*.mp4', '*.avi', '*.mkv', '*.webm', '*.mov', '*.flv', \n",
    "                  '*.mp3', '*.wav', '*.aac', '*.flac', '*.ogg', '*.m4a']\n",
    "    for ext in extensions:\n",
    "        files_to_process.extend(glob.glob(os.path.join(SOURCE_INPUT, '**', ext), recursive=True))\n",
    "    print(f\"üìä {len(files_to_process)} fichiers trouv√©s\")\n",
    "\n",
    "elif SOURCE_TYPE == \"3\":  # Fichier\n",
    "    if os.path.isfile(SOURCE_INPUT):\n",
    "        files_to_process.append(SOURCE_INPUT)\n",
    "        print(f\"üìÑ Fichier s√©lectionn√© : {os.path.basename(SOURCE_INPUT)}\")\n",
    "\n",
    "print(f\"\\nüìã Nombre de fichiers √† traiter : {len(files_to_process)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Transcription et traduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traitement de chaque fichier\n",
    "for i, file_path in enumerate(files_to_process, 1):\n",
    "    print(f\"\\nüìÅ Fichier {i}/{len(files_to_process)}: {os.path.basename(file_path)}\")\n",
    "    \n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    output_base = os.path.join(temp_directory, base_name)\n",
    "    \n",
    "    # Conversion si n√©cessaire\n",
    "    file_type = detect_file_type(file_path)\n",
    "    if file_type == \"audio\":\n",
    "        audio_source = file_path\n",
    "    elif file_type == \"video\":\n",
    "        audio_source = output_base + \".mp3\"\n",
    "        print(f\"üîÑ Conversion vid√©o ‚Üí audio...\")\n",
    "        command = [\"ffmpeg\", \"-i\", file_path, \"-vn\", \"-acodec\", \"libmp3lame\", \"-q:a\", \"0\", \"-y\", audio_source]\n",
    "        subprocess.run(command, check=True, capture_output=True)\n",
    "        print(\"‚úÖ Conversion termin√©e\")\n",
    "    else:\n",
    "        print(f\"‚ùå Type non support√© : {file_path}\")\n",
    "        continue\n",
    "    \n",
    "    # D√©tection de langue\n",
    "    print(\"üîç D√©tection de la langue...\")\n",
    "    detected_lang, confidence = detect_language(whisper_model, audio_source)\n",
    "    lang_name = get_language_name(detected_lang)\n",
    "    print(f\"üåç Langue : {lang_name} ({detected_lang}) - Confiance: {confidence:.2f}\")\n",
    "    \n",
    "    # Transcription\n",
    "    print(f\"üìù Transcription en {lang_name}...\")\n",
    "    result = whisper_model.transcribe(audio_source, language=detected_lang, verbose=False, device=device)\n",
    "    \n",
    "    # Traduction\n",
    "    if detected_lang != 'fr':\n",
    "        print(f\"üîÑ Traduction vers le fran√ßais...\")\n",
    "        \n",
    "        # Traduire le texte complet\n",
    "        translated_text, service_used = translate_text(result[\"text\"], TRANSLATION_SERVICE)\n",
    "        improved_text = improve_french_text(translated_text)\n",
    "        \n",
    "        # Traduire chaque segment\n",
    "        for segment in result[\"segments\"]:\n",
    "            segment[\"text_original\"] = segment[\"text\"]\n",
    "            translated_segment, _ = translate_text(segment[\"text\"], TRANSLATION_SERVICE)\n",
    "            segment[\"text_fr\"] = improve_french_text(translated_segment)\n",
    "        \n",
    "        print(f\"‚úÖ Traduction termin√©e avec {service_used}\")\n",
    "    else:\n",
    "        print(\"üá´üá∑ Audio d√©j√† en fran√ßais\")\n",
    "        improved_text = improve_french_text(result[\"text\"])\n",
    "        for segment in result[\"segments\"]:\n",
    "            segment[\"text_original\"] = segment[\"text\"]\n",
    "            segment[\"text_fr\"] = improve_french_text(segment[\"text\"])\n",
    "        service_used = \"none\"\n",
    "    \n",
    "    # Sauvegarde\n",
    "    print(\"üíæ Sauvegarde des fichiers...\")\n",
    "    \n",
    "    # Texte fran√ßais\n",
    "    french_text_file = output_base + \"_fr.txt\"\n",
    "    with open(french_text_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(improved_text)\n",
    "    generated_files.append(french_text_file)\n",
    "    print(f\"‚úÖ {os.path.basename(french_text_file)}\")\n",
    "    \n",
    "    # Texte original (si diff√©rent)\n",
    "    if EXPORT_BILINGUAL and detected_lang != \"fr\":\n",
    "        original_text_file = output_base + \"_original.txt\"\n",
    "        with open(original_text_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(result[\"text\"])\n",
    "        generated_files.append(original_text_file)\n",
    "        print(f\"‚úÖ {os.path.basename(original_text_file)}\")\n",
    "    \n",
    "    # SRT fran√ßais\n",
    "    french_srt_file = output_base + \"_fr.srt\"\n",
    "    with open(french_srt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        for j, segment in enumerate(result[\"segments\"]):\n",
    "            start_time = format_timestamp(segment[\"start\"])\n",
    "            end_time = format_timestamp(segment[\"end\"])\n",
    "            text = segment.get(\"text_fr\", segment[\"text\"]).strip()\n",
    "            f.write(f\"{j+1}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")\n",
    "    generated_files.append(french_srt_file)\n",
    "    print(f\"‚úÖ {os.path.basename(french_srt_file)}\")\n",
    "    \n",
    "    # SRT bilingue (si activ√©)\n",
    "    if EXPORT_BILINGUAL and detected_lang != \"fr\":\n",
    "        bilingual_srt_file = output_base + \"_bilingue.srt\"\n",
    "        with open(bilingual_srt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for j, segment in enumerate(result[\"segments\"]):\n",
    "                start_time = format_timestamp(segment[\"start\"])\n",
    "                end_time = format_timestamp(segment[\"end\"])\n",
    "                original = segment.get(\"text_original\", segment[\"text\"]).strip()\n",
    "                french = segment.get(\"text_fr\", segment[\"text\"]).strip()\n",
    "                f.write(f\"{j+1}\\n{start_time} --> {end_time}\\n{original}\\n{french}\\n\\n\")\n",
    "        generated_files.append(bilingual_srt_file)\n",
    "        print(f\"‚úÖ {os.path.basename(bilingual_srt_file)}\")\n",
    "    \n",
    "    # M√©tadonn√©es JSON\n",
    "    metadata_file = output_base + \"_metadata.json\"\n",
    "    metadata = {\n",
    "        \"source_file\": os.path.basename(file_path),\n",
    "        \"source_language\": detected_lang,\n",
    "        \"source_language_name\": lang_name,\n",
    "        \"language_confidence\": confidence,\n",
    "        \"translation_service\": service_used,\n",
    "        \"processed_at\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"whisper_model\": whisper_model_name,\n",
    "        \"device\": device\n",
    "    }\n",
    "    with open(metadata_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metadata, f, indent=2, ensure_ascii=False)\n",
    "    generated_files.append(metadata_file)\n",
    "    print(f\"‚úÖ {os.path.basename(metadata_file)}\")\n",
    "\n",
    "print(\"\\nüéâ TRAITEMENT TERMIN√â !\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Fichiers trait√©s : {len(files_to_process)}\")\n",
    "print(f\"üìù Fichiers g√©n√©r√©s : {len(generated_files)}\")\n",
    "print(f\"üìÇ R√©pertoire : {temp_directory}\")\n",
    "print(\"\\nüìÑ Fichiers g√©n√©r√©s :\")\n",
    "for file_path in generated_files:\n",
    "    print(f\"  ‚úÖ {os.path.basename(file_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cr√©ation d'archive (optionnel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'une archive ZIP\n",
    "CREATE_ARCHIVE = True\n",
    "\n",
    "if CREATE_ARCHIVE and generated_files:\n",
    "    timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    archive_path = os.path.join(temp_directory, f\"transcriptions_fr_{timestamp}.zip\")\n",
    "    \n",
    "    print(f\"üì¶ Cr√©ation de l'archive : {os.path.basename(archive_path)}\")\n",
    "    \n",
    "    with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file_path in generated_files:\n",
    "            if os.path.exists(file_path):\n",
    "                zipf.write(file_path, os.path.basename(file_path))\n",
    "    \n",
    "    print(f\"‚úÖ Archive cr√©√©e : {archive_path}\")\n",
    "    print(f\"üìä Taille : {os.path.getsize(archive_path) / 1024:.1f} KB\")\n",
    "else:\n",
    "    print(\"üì¶ Cr√©ation d'archive d√©sactiv√©e\")\n",
    "\n",
    "print(\"\\nüéØ WHISPER TRANSCRIPTION + TRANSLATION v2.1 - TERMIN√â ‚úÖ\")\n",
    "print(\"Tous vos fichiers traduits en fran√ßais sont pr√™ts !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
