{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c796b015",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-01T01:12:49.300202Z",
     "iopub.status.busy": "2024-08-01T01:12:49.299667Z",
     "iopub.status.idle": "2024-08-01T01:12:50.052660Z",
     "shell.execute_reply": "2024-08-01T01:12:50.051902Z"
    },
    "papermill": {
     "duration": 0.76093,
     "end_time": "2024-08-01T01:12:50.054906",
     "exception": false,
     "start_time": "2024-08-01T01:12:49.293976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3bcc0c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T01:12:50.064118Z",
     "iopub.status.busy": "2024-08-01T01:12:50.063324Z",
     "iopub.status.idle": "2024-08-01T01:13:25.119141Z",
     "shell.execute_reply": "2024-08-01T01:13:25.118216Z"
    },
    "papermill": {
     "duration": 35.06268,
     "end_time": "2024-08-01T01:13:25.121529",
     "exception": false,
     "start_time": "2024-08-01T01:12:50.058849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ffmpeg in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (1.4)\n",
      "Requirement already satisfied: yt_dlp in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (2025.4.30)\n",
      "Requirement already satisfied: huggingface_hub in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (0.31.4)\n",
      "Requirement already satisfied: filelock in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from huggingface_hub) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from huggingface_hub) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from huggingface_hub) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests->huggingface_hub) (2025.4.26)\n",
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-8v0xxmfq\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-8v0xxmfq\n",
      "  Resolved https://github.com/openai/whisper.git to commit dd985ac4b90cafeef8712f2998d62c59c3e62d22\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: more-itertools in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from openai-whisper==20240930) (10.7.0)\n",
      "Requirement already satisfied: numba in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from openai-whisper==20240930) (0.61.2)\n",
      "Requirement already satisfied: numpy in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from openai-whisper==20240930) (2.2.6)\n",
      "Requirement already satisfied: tiktoken in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from openai-whisper==20240930) (0.9.0)\n",
      "Requirement already satisfied: torch in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from openai-whisper==20240930) (2.7.0)\n",
      "Requirement already satisfied: tqdm in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from openai-whisper==20240930) (4.67.1)\n",
      "Requirement already satisfied: triton>=2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from openai-whisper==20240930) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from triton>=2->openai-whisper==20240930) (65.5.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from numba->openai-whisper==20240930) (0.44.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2025.4.26)\n",
      "Requirement already satisfied: filelock in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch->openai-whisper==20240930) (1.11.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->openai-whisper==20240930) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n",
      "Requirement already satisfied: torch in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchaudio in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (0.22.0)\n",
      "Requirement already satisfied: filelock in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from triton==3.3.0->torch) (65.5.0)\n",
      "Requirement already satisfied: numpy in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/nzonzi/Documents/Prompting/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Cellule 1: Installation des dépendances\n",
    "!pip install ffmpeg yt_dlp huggingface_hub\n",
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install torch torchaudio torchvision  # S'assurer que PyTorch est installé pour Whisper et GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d405d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e4a3e74",
   "metadata": {
    "papermill": {
     "duration": 0.010061,
     "end_time": "2024-08-01T01:13:25.142000",
     "exception": false,
     "start_time": "2024-08-01T01:13:25.131939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Traduire une vidéo YT en Français\n",
    "# Ajout de la Transcription + Traduction + SRT dans la foulée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "947a40aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T01:13:25.163701Z",
     "iopub.status.busy": "2024-08-01T01:13:25.163409Z",
     "iopub.status.idle": "2024-08-01T01:13:25.556969Z",
     "shell.execute_reply": "2024-08-01T01:13:25.555819Z"
    },
    "papermill": {
     "duration": 0.406428,
     "end_time": "2024-08-01T01:13:25.558528",
     "exception": true,
     "start_time": "2024-08-01T01:13:25.152100",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cellule 2: Définition des fonctions utilitaires\n",
    "import os\n",
    "import subprocess\n",
    "import argparse # Importer argparse\n",
    "from yt_dlp import YoutubeDL\n",
    "import whisper\n",
    "import zipfile # Importer zipfile\n",
    "import glob # Importer glob pour la recherche de fichiers\n",
    "from huggingface_hub import HfApi, login # Importer pour Hugging Face\n",
    "import time # Pour horodatage de l'archive de sortie\n",
    "import shutil # Pour le nettoyage\n",
    "import torch # Pour la gestion GPU\n",
    "\n",
    "# --- Définition des fonctions ---\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    milliseconds = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
    "\n",
    "def download_video(url, temp_dir):\n",
    "    \"\"\"Télécharge une vidéo depuis une URL.\"\"\"\n",
    "    print(f\"Téléchargement de la vidéo depuis {url}...\")\n",
    "    ydl_opts = {\n",
    "        'format': 'bestvideo+bestaudio/best',\n",
    "        'outtmpl': os.path.join(temp_dir, '%(title)s.%(ext)s'),\n",
    "        'cleanup': True,\n",
    "        'noplaylist': True, # S'assurer de ne télécharger qu'une seule vidéo\n",
    "        'quiet': True, # Supprimer la sortie verbeuse de yt_dlp\n",
    "        'no_progress': True, # Supprimer les barres de progression\n",
    "    }\n",
    "    video_filepath = None\n",
    "    try:\n",
    "        with YoutubeDL(ydl_opts) as ydl:\n",
    "            info_dict = ydl.extract_info(url, download=True)\n",
    "            # yt_dlp retourne parfois des noms de fichiers avec des extensions non finales,\n",
    "            # ou dans des sous-dossiers si 'outtmpl' contient des répertoires.\n",
    "            # Une approche plus robuste est de chercher le fichier téléchargé.\n",
    "            # Le champ 'requested_downloads' ou 'filename' dans info_dict peut aussi aider.\n",
    "            # Pour simplifier ici, on va se baser sur le titre et chercher.\n",
    "            potential_filename = info_dict.get('filename')\n",
    "            if potential_filename and os.path.exists(potential_filename):\n",
    "                 video_filepath = potential_filename\n",
    "            else:\n",
    "                # Fallback: chercher dans le temp_dir\n",
    "                downloaded_files = glob.glob(os.path.join(temp_dir, info_dict.get('title', '*') + '.*'))\n",
    "                video_extensions = ('.mkv', '.mp4', '.webm', '.avi', '.mov', '.flv') # Ajouter d'autres si besoin\n",
    "                # Trouver le fichier qui n'est PAS un fichier temporaire (.ytdl, .part, etc.) et qui est un format vidéo\n",
    "                video_filepath = next((f for f in downloaded_files if os.path.isfile(f) and not f.endswith(('.ytdl', '.part')) and f.lower().endswith(video_extensions)), None)\n",
    "\n",
    "        if video_filepath is None or not os.path.exists(video_filepath):\n",
    "             raise FileNotFoundError(\"Impossible de trouver le fichier vidéo téléchargé.\")\n",
    "\n",
    "        print(f\"Téléchargement terminé : {video_filepath}\")\n",
    "        return video_filepath\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du téléchargement de la vidéo {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def convert_video_to_audio(video_path, audio_path):\n",
    "    \"\"\"Convertit une vidéo en fichier audio en utilisant ffmpeg.\"\"\"\n",
    "    print(f\"Conversion de {os.path.basename(video_path)} en audio ({audio_path})...\")\n",
    "    if not os.path.exists(video_path):\n",
    "         print(f\"Erreur: Fichier vidéo source introuvable pour conversion audio : {video_path}\")\n",
    "         return False\n",
    "\n",
    "    # Ajouter un check si ffmpeg est installé\n",
    "    try:\n",
    "        subprocess.run([\"ffmpeg\", \"-version\"], check=True, capture_output=True, text=True)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Erreur : ffmpeg n'est pas installé ou n'est pas dans le PATH.\")\n",
    "        print(\"Veuillez installer ffmpeg pour continuer (ex: !apt-get update && apt-get install ffmpeg).\")\n",
    "        return False # Indiquer l'échec\n",
    "\n",
    "    try:\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-i\", video_path,\n",
    "            \"-vn\", # Supprimer la vidéo\n",
    "            \"-acodec\", \"libmp3lame\", # Encoder en MP3\n",
    "            \"-q:a\", \"0\", # Qualité audio maximale\n",
    "            \"-map\", \"a\", # Sélectionner le flux audio\n",
    "            \"-y\", # Écraser le fichier de sortie s'il existe déjà\n",
    "            audio_path\n",
    "        ]\n",
    "\n",
    "        subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "        print(\"Conversion audio terminée.\")\n",
    "        return True # Indiquer le succès\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Erreur lors de la conversion vidéo en audio : {e.stderr}\")\n",
    "        return False # Indiquer l'échec\n",
    "    except Exception as e:\n",
    "        print(f\"Une erreur inattendue est survenue lors de la conversion audio : {e}\")\n",
    "        return False # Indiquer l'échec\n",
    "\n",
    "\n",
    "def transcribe_audio(model, audio_path, device=\"auto\"):\n",
    "    \"\"\"Transcrire un fichier audio en utilisant le modèle Whisper.\"\"\"\n",
    "    print(f\"Transcription de {os.path.basename(audio_path)} avec Whisper (device: {device})...\")\n",
    "    if not os.path.exists(audio_path):\n",
    "         print(f\"Erreur: Fichier audio source introuvable pour transcription : {audio_path}\")\n",
    "         return None\n",
    "\n",
    "    try:\n",
    "        # Charger le modèle sur le bon device.\n",
    "        # Si device=\"auto\", Whisper choisira la meilleure option (CPU ou GPU 0)\n",
    "        # Pour spécifier un GPU, utilise \"cuda:0\", \"cuda:1\", etc.\n",
    "        # Pour forcer le CPU, utilise \"cpu\".\n",
    "        # model.to(device) # Le modèle est déjà chargé, il faut l'envoyer sur le device\n",
    "        # Note: Whisper ne gère pas nativement le multi-GPU sur une seule tâche de transcription.\n",
    "        # Pour utiliser plusieurs GPUs, il faudrait paralléliser le traitement de plusieurs fichiers\n",
    "        # ou utiliser une implémentation différente comme faster-whisper.\n",
    "        # Ici, on s'assure juste qu'il utilise *un* GPU si possible et permet de choisir lequel.\n",
    "        # La fonction transcribe() de Whisper peut prendre un argument device.\n",
    "\n",
    "        result = model.transcribe(audio_path, language=\"fr\", verbose=False)\n",
    "        print(\"Transcription terminée.\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la transcription audio : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_transcription(result, base_path):\n",
    "    \"\"\"Sauvegarde la transcription en format .txt et .srt.\"\"\"\n",
    "    if result is None:\n",
    "        print(f\"Aucun résultat de transcription à sauvegarder pour {base_path}.\")\n",
    "        return None, None # Retourner None pour les chemins de fichiers\n",
    "\n",
    "    text_file = base_path + \".txt\"\n",
    "    srt_file = base_path + \".srt\"\n",
    "\n",
    "    print(f\"Sauvegarde de la transcription dans {text_file} et {srt_file}...\")\n",
    "\n",
    "    try:\n",
    "        with open(text_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(result[\"text\"])\n",
    "\n",
    "        with open(srt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for i, segment in enumerate(result[\"segments\"]):\n",
    "                start_time = format_timestamp(segment[\"start\"])\n",
    "                end_time = format_timestamp(segment[\"end\"])\n",
    "                text = segment[\"text\"].strip()\n",
    "                f.write(f\"{i+1}\\\\n{start_time} --> {end_time}\\\\n{text}\\\\n\\\\n\")\n",
    "        print(\"Sauvegarde terminée.\")\n",
    "        return text_file, srt_file # Retourner les chemins des fichiers sauvegardés\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde des fichiers de transcription pour {base_path}: {e}\")\n",
    "        return None, None # Retourner None en cas d'erreur\n",
    "\n",
    "def extract_archive(archive_path, extract_dir):\n",
    "    \"\"\"Extrait une archive (zip) dans un répertoire spécifié.\"\"\"\n",
    "    print(f\"Extraction de l'archive {archive_path} dans {extract_dir}...\")\n",
    "    if not os.path.exists(archive_path):\n",
    "        print(f\"Erreur: Fichier archive introuvable : {archive_path}\")\n",
    "        return False\n",
    "    try:\n",
    "        with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "        print(\"Extraction terminée.\")\n",
    "        return True\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"Erreur : {archive_path} n'est pas un fichier Zip valide.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'extraction de l'archive {archive_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def find_video_files(directory):\n",
    "    \"\"\"Trouve tous les fichiers vidéo dans un répertoire donné (récursif).\"\"\"\n",
    "    video_extensions = ['*.mkv', '*.mp4', '*.webm', '*.avi', '*.mov', '*.flv']\n",
    "    video_list = []\n",
    "    print(f\"Recherche de fichiers vidéo dans le répertoire {directory}...\")\n",
    "    if not os.path.isdir(directory):\n",
    "        print(f\"Erreur: Le chemin fourni n'est pas un répertoire : {directory}\")\n",
    "        return []\n",
    "    for ext in video_extensions:\n",
    "        video_list.extend(glob.glob(os.path.join(directory, '**', ext), recursive=True))\n",
    "    print(f\"Trouvé {len(video_list)} fichiers vidéo.\")\n",
    "    return video_list\n",
    "\n",
    "def process_video_file(video_or_audio_path, temp_dir, whisper_model, device=\"auto\"):\n",
    "    \"\"\"\n",
    "    Traite un seul fichier vidéo ou audio :\n",
    "    convertit en audio si nécessaire, transcrit et sauvegarde.\n",
    "    \"\"\"\n",
    "    print(f\"\\\\n--- Traitement de {os.path.basename(video_or_audio_path)} ---\")\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(video_or_audio_path))[0]\n",
    "    audio_file_path = os.path.join(temp_dir, base_name + \".mp3\")\n",
    "    base_path_output = os.path.join(temp_dir, base_name)\n",
    "\n",
    "    # Déterminer si l'entrée est déjà un fichier audio\n",
    "    is_audio_input = video_or_audio_path.lower().endswith(('.mp3', '.wav', '.aac', '.flac', '.ogg')) # Ajoute d'autres extensions audio si besoin\n",
    "\n",
    "    final_audio_source = None\n",
    "\n",
    "    if is_audio_input:\n",
    "        # Si l'entrée est déjà un audio, utiliser ce fichier directement pour la transcription\n",
    "        print(f\"L'entrée est un fichier audio, utilisation directe : {os.path.basename(video_or_audio_path)}\")\n",
    "        final_audio_source = video_or_audio_path\n",
    "        # On peut optionnellement copier le fichier audio vers temp_dir si on veut le nettoyer plus tard\n",
    "        # shutil.copy2(video_or_audio_path, audio_file_path)\n",
    "        # final_audio_source = audio_file_path # Utiliser la copie\n",
    "    else:\n",
    "        # Si l'entrée est une vidéo, convertir en audio\n",
    "        if not os.path.exists(audio_file_path):\n",
    "            if convert_video_to_audio(video_or_audio_path, audio_file_path):\n",
    "                final_audio_source = audio_file_path\n",
    "            else:\n",
    "                print(f\"Skipping transcription for {os.path.basename(video_or_audio_path)} due to audio conversion error.\")\n",
    "                return None, None # Retourner None si la conversion échoue\n",
    "        else:\n",
    "            print(f\"Audio file already exists: {audio_file_path}\")\n",
    "            final_audio_source = audio_file_path # Utiliser le fichier audio existant\n",
    "\n",
    "    if final_audio_source:\n",
    "        # Transcrire l'audio (qu'il vienne d'une conversion ou soit l'entrée directe)\n",
    "        transcription_result = transcribe_audio(whisper_model, final_audio_source)\n",
    "\n",
    "        # Sauvegarder la transcription\n",
    "        text_path, srt_path = save_transcription(transcription_result, base_path_output)\n",
    "\n",
    "        print(f\"--- Fin du traitement de {os.path.basename(video_or_audio_path)} ---\")\n",
    "\n",
    "        # Retourner les chemins des fichiers générés (.txt et .srt)\n",
    "        return text_path, srt_path\n",
    "    else:\n",
    "        # Aucun source audio finale disponible\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def create_output_archive(files_to_archive, output_archive_path):\n",
    "    \"\"\"Crée une archive zip contenant les fichiers spécifiés.\"\"\"\n",
    "    if not files_to_archive:\n",
    "        print(\"Aucun fichier à archiver.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"Création de l'archive de sortie {output_archive_path}...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(output_archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            for file_path in files_to_archive:\n",
    "                if os.path.exists(file_path):\n",
    "                    # Ajouter le fichier à l'archive en conservant uniquement le nom du fichier\n",
    "                    zipf.write(file_path, os.path.basename(file_path))\n",
    "                else:\n",
    "                    print(f\"Avertissement: Le fichier {file_path} n'existe pas et ne sera pas inclus dans l'archive.\")\n",
    "        print(\"Archive de sortie créée avec succès.\")\n",
    "        return output_archive_path\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la création de l'archive de sortie {output_archive_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def upload_to_huggingface(file_path, repo_id, repo_type=\"dataset\", path_in_repo=None, commit_message=None):\n",
    "    \"\"\"Charge un fichier vers un dépôt Hugging Face.\"\"\"\n",
    "    print(f\"Tentative de chargement de {file_path} vers Hugging Face repo '{repo_id}'...\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "         print(f\"Erreur : Le fichier à charger {file_path} n'existe pas.\")\n",
    "         return False\n",
    "\n",
    "    # Vérifier si l'utilisateur est authentifié ou si le token est présent\n",
    "    # L'authentification interactive (login()) n'est pas idéale dans un script/notebook non interactif.\n",
    "    # Il est préférable de s'assurer que HUGGING_FACE_HUB_TOKEN est défini comme variable d'environnement.\n",
    "    token = os.environ.get(\"HUGGING_FACE_HUB_TOKEN\")\n",
    "    if not token:\n",
    "         print(\"Erreur : Variable d'environnement HUGGING_FACE_HUB_TOKEN non définie.\")\n",
    "         print(\"Veuillez vous authentifier en utilisant `huggingface-cli login` dans votre terminal ou en définissant la variable d'environnement dans Kaggle Secrets.\")\n",
    "         return False # Indiquer l'échec\n",
    "\n",
    "    try:\n",
    "        api = HfApi()\n",
    "\n",
    "        if path_in_repo is None:\n",
    "             path_in_repo = os.path.basename(file_path) # Charger à la racine du dépôt avec le nom du fichier\n",
    "\n",
    "        api.upload_file(\n",
    "            path_or_fileobj=file_path,\n",
    "            path_in_repo=path_in_repo,\n",
    "            repo_id=repo_id,\n",
    "            repo_type=repo_type, # peut être \"model\", \"dataset\", \"space\"\n",
    "            token=token, # Utiliser le token\n",
    "            commit_message=commit_message if commit_message else f\"Upload {os.path.basename(file_path)}\"\n",
    "        )\n",
    "        print(f\"Fichier {file_path} chargé avec succès vers {repo_id}/{path_in_repo}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement du fichier vers Hugging Face : {e}\")\n",
    "        # Afficher plus de détails si possible\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"Réponse de l'API HF : {e.response.text}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b58fdf3f",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-08-01T00:30:31.542116Z",
     "iopub.status.busy": "2024-08-01T00:30:31.541609Z",
     "iopub.status.idle": "2024-08-01T00:30:34.866012Z",
     "shell.execute_reply": "2024-08-01T00:30:34.865142Z",
     "shell.execute_reply.started": "2024-08-01T00:30:31.542083Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de GPUs disponibles : 1\n",
      "Utilisation du GPU : cuda:0\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/kaggle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 70\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAucun GPU disponible. Utilisation du CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# --- Fin de la Configuration ---\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m \n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# --- Initialisation ---\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m video_files_to_process \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     72\u001b[0m cleanup_temp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# Indique si le répertoire temporaire doit être nettoyé à la fin\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/os.py:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m head \u001b[38;5;129;01mand\u001b[39;00m tail \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mexists(head):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileExistsError\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# Defeats race condition when another thread created the path\u001b[39;00m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/kaggle'"
     ]
    }
   ],
   "source": [
    "# Cellule 3: Configuration et Lancement du Traitement\n",
    "\n",
    "# --- Configuration des paramètres (simule les arguments de ligne de commande) ---\n",
    "# Modifie ces variables pour spécifier ton entrée et tes options de sortie\n",
    "\n",
    "# Choisissez l'une des options suivantes en décommentant et en renseignant la bonne variable:\n",
    "source_type = \"url\"        # Options: \"url\", \"archive\", \"directory\"\n",
    "\n",
    "# --- Paramètres d'entrée ---\n",
    "# Si source_type est \"url\":\n",
    "input_url = 'https://www.youtube.com/watch?v=TLzna9__DnI'\n",
    "# Si source_type est \"archive\":\n",
    "input_archive_path = '/chemin/vers/ton/archive.zip'\n",
    "# Si source_type est \"directory\":\n",
    "input_directory_path = '/chemin/vers/ton/repertoire/de/videos'\n",
    "\n",
    "\n",
    "# --- Paramètres de sortie et temporaires ---\n",
    "temp_directory = '/kaggle/working' # Répertoire pour les fichiers intermédiaires (audio, transcriptions temporaires)\n",
    "output_archive_path = None         # Chemin pour l'archive de sortie des transcriptions (ex: '/kaggle/working/mes_transcriptions.zip' ou '/media/Serva/transcriptions.zip')\n",
    "                                   # Laisse None si tu ne veux pas créer d'archive de sortie\n",
    "\n",
    "\n",
    "# --- Paramètres d'upload Hugging Face ---\n",
    "hf_upload_repo = None      # ID du dépôt Hugging Face (ex: 'ton-nom/ton-depot'). Laisse None pour ne pas uploader.\n",
    "hf_repo_type = \"dataset\"   # Type du dépôt Hugging Face ('model', 'dataset', 'space')\n",
    "# Assure-toi d'avoir configuré ton token Hugging Face (variable d'environnement HUGGING_FACE_HUB_TOKEN dans Kaggle Secrets par exemple)\n",
    "\n",
    "\n",
    "# --- Paramètres Whisper ---\n",
    "whisper_model_name = \"large-v3\"\n",
    "# Gestion du GPU :\n",
    "# Whisper utilise PyTorch. PyTorch gère les GPUs via CUDA.\n",
    "# torch.cuda.is_available() vérifie si un GPU est accessible.\n",
    "# torch.cuda.device_count() donne le nombre de GPUs.\n",
    "# device = \"cuda\" si torch.cuda.is_available() else \"cpu\" utilise le GPU 0 par défaut si disponible.\n",
    "# Pour spécifier un GPU (ex: le deuxième GPU), utilise device = \"cuda:1\".\n",
    "# Pour *forcer* l'utilisation de deux GPUs en parallèle sur une *seule* transcription,\n",
    "# c'est complexe et non géré nativement par la fonction transcribe() de Whisper.\n",
    "# Cela nécessiterait de découper l'audio et de lancer plusieurs processus/threads avec des modèles sur chaque GPU,\n",
    "# ou d'utiliser faster-whisper ou une autre implémentation.\n",
    "# Pour l'instant, nous allons charger le modèle sur UN GPU spécifique si possible.\n",
    "# Si tu as 2 GPUs, tu peux lancer 2 instances de ce script/notebook en parallèle,\n",
    "# chacune configurée pour utiliser un GPU différent (device=\"cuda:0\" et device=\"cuda:1\").\n",
    "# Ou tu peux adapter pour traiter les fichiers en batch, en envoyant chaque fichier à un thread/processus\n",
    "# qui utilise un GPU différent. C'est une modification plus avancée.\n",
    "\n",
    "# Pour utiliser un GPU si disponible (par défaut, souvent cuda:0)\n",
    "# transcription_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Pour forcer l'utilisation d'un GPU spécifique (ex: cuda:1) si disponible:\n",
    "gpu_index_to_use = 0 # Mets 0 ou 1 (ou plus) si tu sais quel GPU tu veux utiliser\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Nombre de GPUs disponibles : {num_gpus}\")\n",
    "    if gpu_index_to_use < num_gpus:\n",
    "        transcription_device = f\"cuda:{gpu_index_to_use}\"\n",
    "        print(f\"Utilisation du GPU : {transcription_device}\")\n",
    "    else:\n",
    "        print(f\"GPU index {gpu_index_to_use} non disponible. Utilisation du GPU 0.\")\n",
    "        transcription_device = \"cuda:0\" # Fallback au GPU 0\n",
    "else:\n",
    "    transcription_device = \"cpu\"\n",
    "    print(\"Aucun GPU disponible. Utilisation du CPU.\")\n",
    "\n",
    "# --- Fin de la Configuration ---\n",
    "\n",
    "\n",
    "# --- Initialisation ---\n",
    "os.makedirs(temp_directory, exist_ok=True)\n",
    "video_files_to_process = []\n",
    "cleanup_temp_dir = False # Indique si le répertoire temporaire doit être nettoyé à la fin\n",
    "\n",
    "\n",
    "# --- Gérer les différentes sources d'entrée ---\n",
    "if source_type == \"url\":\n",
    "    if not input_url:\n",
    "        print(\"Erreur: L'URL n'est pas spécifiée.\")\n",
    "        # exit(1) # N'utilise pas exit() dans un notebook, lève une erreur ou utilise return\n",
    "        raise ValueError(\"L'URL n'est pas spécifiée.\")\n",
    "\n",
    "    video_path = download_video(input_url, temp_directory)\n",
    "    if video_path:\n",
    "        video_files_to_process.append(video_path)\n",
    "    # Nettoyer le fichier vidéo téléchargé après traitement\n",
    "    cleanup_temp_dir = True # On nettoiera le fichier téléchargé\n",
    "\n",
    "elif source_type == \"archive\":\n",
    "    if not input_archive_path or not os.path.exists(input_archive_path):\n",
    "         print(f\"Erreur: Fichier archive introuvable : {input_archive_path}\")\n",
    "         # exit(1)\n",
    "         raise FileNotFoundError(f\"Fichier archive introuvable : {input_archive_path}\")\n",
    "\n",
    "    extract_dir = os.path.join(temp_directory, \"extracted_archive\")\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    if extract_archive(input_archive_path, extract_dir):\n",
    "         video_files_to_process = find_video_files(extract_dir)\n",
    "         cleanup_temp_dir = True # Nettoyer le répertoire d'extraction après traitement\n",
    "    else:\n",
    "         print(\"Impossible de traiter l'archive.\")\n",
    "         # exit(1)\n",
    "         raise RuntimeError(\"Impossible de traiter l'archive.\")\n",
    "\n",
    "elif source_type == \"directory\":\n",
    "    if not input_directory_path or not os.path.isdir(input_directory_path):\n",
    "         print(f\"Erreur: Répertoire introuvable : {input_directory_path}\")\n",
    "         # exit(1)\n",
    "         raise FileNotFoundError(f\"Répertoire introuvable : {input_directory_path}\")\n",
    "\n",
    "    video_files_to_process = find_video_files(input_directory_path)\n",
    "    # Ne pas nettoyer le répertoire d'entrée s'il a été fourni directement\n",
    "    cleanup_temp_dir = False # Ne pas supprimer les fichiers originaux\n",
    "\n",
    "else:\n",
    "    print(f\"Erreur: Type de source '{source_type}' non reconnu.\")\n",
    "    # exit(1)\n",
    "    raise ValueError(f\"Type de source '{source_type}' non reconnu.\")\n",
    "\n",
    "\n",
    "if not video_files_to_process:\n",
    "    print(\"Aucun fichier vidéo/audio valide trouvé pour le traitement.\")\n",
    "    # exit(0) # N'utilise pas exit(0) qui arrête le kernel, utilise return si dans une fonction ou laisse passer\n",
    "    # Si tu veux arrêter ici, tu peux décommenter le raise ValueError ci-dessous\n",
    "    # raise ValueError(\"Aucun fichier vidéo/audio valide trouvé pour le traitement.\")\n",
    "\n",
    "\n",
    "# --- Charger le modèle Whisper ---\\n\",\n",
    "print(f\"Chargement du modèle Whisper '{whisper_model_name}' sur {transcription_device}...\")\n",
    "try:\n",
    "    # Charger le modèle sur le bon device dès le départ\n",
    "    whisper_model = whisper.load_model(whisper_model_name, device=transcription_device)\n",
    "    print(\"Modèle Whisper chargé.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement du modèle Whisper : {e}\")\n",
    "    # exit(1)\n",
    "    raise RuntimeError(f\"Erreur lors du chargement du modèle Whisper : {e}\")\n",
    "\n",
    "\n",
    "# --- Traiter chaque fichier vidéo/audio trouvé ---\\n\",\n",
    "all_generated_files = []\n",
    "for video_file_path in video_files_to_process:\n",
    "     # Passer le device à la fonction de transcription\n",
    "     text_path, srt_path = process_video_file(video_file_path, temp_directory, whisper_model, device=transcription_device)\n",
    "     if text_path:\n",
    "          all_generated_files.append(text_path)\n",
    "     if srt_path:\n",
    "          all_generated_files.append(srt_path)\n",
    "\n",
    "\n",
    "# --- Créer l'archive de sortie si demandée ---\\n\",\n",
    "output_archive_created = None\n",
    "if output_archive_path:\n",
    "    # S'assurer que le répertoire de sortie existe\n",
    "    output_archive_dir = os.path.dirname(output_archive_path)\n",
    "    if output_archive_dir and not os.path.exists(output_archive_dir): # S'assurer que ce n'est pas juste un nom de fichier\n",
    "        os.makedirs(output_archive_dir, exist_ok=True)\n",
    "        print(f\"Répertoire de sortie créé : {output_archive_dir}\")\n",
    "\n",
    "    output_archive_created = create_output_archive(all_generated_files, output_archive_path)\n",
    "\n",
    "# --- Charger vers Hugging Face si demandé ---\\n\",\n",
    "if hf_upload_repo:\n",
    "    files_to_upload = []\n",
    "    if output_archive_created:\n",
    "        # Si une archive de sortie a été créée, on charge l'archive\n",
    "        print(\"Une archive de sortie a été créée, chargement de l'archive vers Hugging Face.\")\n",
    "        files_to_upload.append(output_archive_created)\n",
    "    else:\n",
    "        # Sinon, on charge les fichiers .txt et .srt individuels\n",
    "        print(\"Aucune archive de sortie spécifiée ou créée, chargement des fichiers individuels (.txt, .srt) vers Hugging Face.\")\n",
    "        files_to_upload.extend(all_generated_files)\n",
    "\n",
    "    if not files_to_upload:\n",
    "        print(\"Aucun fichier à charger vers Hugging Face.\")\n",
    "    else:\n",
    "        print(\"\\\\n--- Chargement vers Hugging Face ---\")\n",
    "        # Générer un timestamp unique pour les uploads individuels si pas d'archive\n",
    "        timestamp_folder = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        for file_path_to_upload in files_to_upload:\n",
    "             # Définir le chemin dans le dépôt HF\n",
    "             path_in_repo = None\n",
    "             if not output_archive_created: # C'est un fichier individuel, pas l'archive\n",
    "                 path_in_repo = f\"transcriptions/{timestamp_folder}/{os.path.basename(file_path_to_upload)}\"\n",
    "             else: # C'est l'archive, on la met à la racine (ou spécifie un sous-dossier si voulu)\n",
    "                  path_in_repo = os.path.basename(file_path_to_upload)\n",
    "\n",
    "\n",
    "             upload_to_huggingface(\n",
    "                 file_path_to_upload,\n",
    "                 repo_id=hf_upload_repo,\n",
    "                 repo_type=hf_repo_type,\n",
    "                 path_in_repo=path_in_repo,\n",
    "                 commit_message=f\"Upload transcription files from run {timestamp_folder}\"\n",
    "             )\n",
    "        print(\"--- Fin du chargement vers Hugging Face ---\")\n",
    "\n",
    "\n",
    "# --- Nettoyage ---\\n\",\n",
    "# Nettoyer uniquement le répertoire temporaire si l'entrée était une URL ou une archive\n",
    "# Si l'entrée était un répertoire, on ne supprime rien dans ce répertoire\n",
    "if cleanup_temp_dir and os.path.exists(temp_directory):\n",
    "     print(f\"Nettoyage du répertoire temporaire : {temp_directory}...\")\n",
    "     # Supprimer les fichiers audio intermédiaires et les fichiers vidéo téléchargés/extraits\n",
    "     # Ne pas supprimer les fichiers .txt ou .srt s'ils ont été créés ici et qu'une archive de sortie n'a pas été spécifiée\n",
    "     # Sauf si une archive de sortie a été demandée, dans ce cas les temporaires (y compris txt/srt) peuvent être nettoyés si non nécessaires ailleurs\n",
    "     files_to_keep_if_no_archive_and_no_hf_upload = all_generated_files if not output_archive_created and not hf_upload_repo else []\n",
    "\n",
    "\n",
    "     for item in os.listdir(temp_directory):\n",
    "         item_path = os.path.join(temp_directory, item)\n",
    "         if os.path.isfile(item_path) and item_path not in files_to_keep_if_no_archive_and_no_hf_upload:\n",
    "             # Nettoyer les fichiers temporaires, sauf si ce sont les outputs finaux (txt/srt) et qu'il n'y a pas d'archive/upload HF\n",
    "             # et sauf l'archive de sortie elle-même si elle a été créée ici.\n",
    "             if item_path != output_archive_created:\n",
    "                 try:\n",
    "                     os.remove(item_path)\n",
    "                 except Exception as e:\n",
    "                     print(f\"Avertissement: Impossible de supprimer le fichier temporaire {item_path}: {e}\")\n",
    "             elif item_path == output_archive_created and not hf_upload_repo:\n",
    "                 # Si l'archive de sortie a été créée mais PAS uploadée sur HF, on la laisse.\n",
    "                 pass # Ne pas supprimer l'archive si elle est le résultat final et pas uploadée\n",
    "             elif item_path == output_archive_created and hf_upload_repo:\n",
    "                  # Si l'archive de sortie a été créée ET uploadée, on peut la supprimer\n",
    "                 try:\n",
    "                     os.remove(item_path)\n",
    "                 except Exception as e:\n",
    "                     print(f\"Avertissement: Impossible de supprimer l'archive de sortie temporaire {item_path} après upload: {e}\")\n",
    "\n",
    "         elif os.path.isdir(item_path) and item == \"extracted_archive\": # Supprimer le répertoire d'extraction\n",
    "             try:\n",
    "                 shutil.rmtree(item_path)\n",
    "             except Exception as e:\n",
    "                  print(f\"Avertissement: Impossible de supprimer le répertoire temporaire {item_path}: {e}\")\n",
    "     print(\"Nettoyage terminé.\")\n",
    "\n",
    "print(\"\\\\nProcessus terminé.\")\n",
    "print(f\"Fichiers de transcription générés : {all_generated_files}\")\n",
    "if output_archive_created:\n",
    "     print(f\"Archive de sortie créée : {output_archive_created}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce87edc2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "** Seconde Video à traiter **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a2ad82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Transcription d'audio MP3 #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c085e22",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "https://youtu.be/afUrxn0NT2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68280d63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-01T00:45:08.361052Z",
     "iopub.status.busy": "2024-08-01T00:45:08.360384Z",
     "iopub.status.idle": "2024-08-01T01:06:40.127009Z",
     "shell.execute_reply": "2024-08-01T01:06:40.125918Z",
     "shell.execute_reply.started": "2024-08-01T00:45:08.361018Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import whisper\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    milliseconds = int((seconds % 1) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{seconds:02},{milliseconds:03}\"\n",
    "\n",
    "def convert_video_to_audio(video_path, audio_path, start_time=\"00:00:00\", stop_time=\"01:00:00\"):\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            \"ffmpeg\",\n",
    "            \"-ss\", start_time,  # Ajoute le point de départ\n",
    "            \"-to\", stop_time,   # Ajoute le point de arrivé\n",
    "            \"-i\", video_path,\n",
    "            \"-q:a\", \"0\",\n",
    "            \"-map\", \"a\",\n",
    "            \"-y\",\n",
    "            audio_path\n",
    "        ], check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        raise RuntimeError(f\"Error converting video to audio: {e}\")\n",
    "\n",
    "def transcribe_audio(model, audio_path):\n",
    "    try:\n",
    "        result = model.transcribe(audio_path, language=\"fr\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error transcribing audio: {e}\")\n",
    "\n",
    "def save_transcription(result, base_path):\n",
    "    text_file = base_path + \".txt\"\n",
    "    srt_file = base_path + \".srt\"\n",
    "\n",
    "    with open(text_file, \"w\") as f:\n",
    "        f.write(result[\"text\"])\n",
    "\n",
    "    with open(srt_file, \"w\") as f:\n",
    "        for i, segment in enumerate(result[\"segments\"]):\n",
    "            start_time = format_timestamp(segment[\"start\"])\n",
    "            end_time = format_timestamp(segment[\"end\"])\n",
    "            text = segment[\"text\"].strip()\n",
    "            f.write(f\"{i+1}\\n{start_time} --> {end_time}\\n{text}\\n\\n\")\n",
    "\n",
    "# Parameters\n",
    "url = input(\"Enter the audio URL: \")\n",
    "temp_dir = '/kaggle/working'\n",
    "!cd /kaggle/working;wget $url\n",
    "\n",
    "# Download the video\n",
    "#try:\n",
    "#    download_video(url, temp_dir)\n",
    "#except Exception as e:\n",
    "#    print(f\"Error downloading video: {e}\")\n",
    "#    exit(1)\n",
    "\n",
    "# Get the downloaded file's name\n",
    "try:\n",
    "    audio_file = [f for f in os.listdir(temp_dir) if f.endswith(('.mp3', '.mkv', '.mp4', '.webm'))][0]\n",
    "except IndexError:\n",
    "    print(\"Error: No audio/video file found in the specified directory.\")\n",
    "    exit(1)\n",
    "\n",
    "audio_path = os.path.join(temp_dir, audio_file)\n",
    "#audio_file = audio_path.rsplit('.', 1)[0] + \".mp3\"\n",
    "\n",
    "# Convert video to audio\n",
    "if not os.path.exists(audio_file):\n",
    "    try:\n",
    "        convert_video_to_audio(video_path, audio_file)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        exit(1)\n",
    "else:\n",
    "    print(f\"Audio file already exists: {audio_file}\")\n",
    "\n",
    "# Load Whisper model and transcribe\n",
    "try:\n",
    "    model = whisper.load_model(\"large-v3\")\n",
    "    transcription_result = transcribe_audio(model, audio_file)\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "    exit(1)\n",
    "\n",
    "# Save the transcription to text and SRT files\n",
    "base_path = audio_file.rsplit('.', 1)[0]\n",
    "save_transcription(transcription_result, base_path)\n",
    "\n",
    "print(f\"Processing complete. Files saved in {temp_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b5838",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!ffmpeg -i \"/kaggle/working/chatGPT： Récupérer le texte FR d'une capsule Youtube US.mkv\" -af \"volume=3\" output.mkv\n",
    "#!rm -rf *.{webm,mp4,mp3,mkv,srt,txt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d2806e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#rm /kaggle/working/'\"Overclocking and Fan Control for Nvidia GPUs in Linux - Comprehensive Guide\".mp4'\n",
    "#!ffmpeg -i \"/kaggle/working/Overclocking and Fan Control for Nvidia GPUs in Linux - Comprehensive Guide.mp4\"   \"/kaggle/working/Overclocking and Fan Control for Nvidia GPUs in Linux - Comprehensive Guide.mp4\" -vn -acodec mp3  \"Linux GPU Overclocking Guide – GreenWithEnvy & CoreCtrl [iUhht9sfG_4].mp3\"\n",
    "#!ls -lad /kaggle/working/* #; rm -rf *.{webm,mp4,mp3,srt,txt}"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39.386693,
   "end_time": "2024-08-01T01:13:25.886593",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-01T01:12:46.499900",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
